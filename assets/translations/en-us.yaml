##############################
# Special stuff
##############################
generic:
  add: Add
  back: Back
  cancel: Cancel
  clickToShow: "[Show Value]"
  close: Close
  comingSoon: Coming Soon
  create: Create
  created: Created
  customize: Customize
  default: Default
  disabled: Disabled
  enabled: Enabled
  enforced: Enforced
  ignored: Ignored
  labelsAndAnnotations: Labels and Annotations
  na: n/a
  name: Name
  none: None
  number: '{prefix}{value, number}{suffix}'
  overview: Overview
  plusMore: + {n} more
  readFromFile: Read from File
  remove: Remove
  resource: |-
    {count, plural,
    one  {resource}
    other {resources}
    }
  save: Save
  type: Type
  unknown: Unknown

locale:
  en-us: English
  none: (None)

nav:
  title: Dashboard
  backToRancher: Cluster Manager
  shell: Shell
  group:
    cluster: Cluster
    inUse: More Resources
    rbac: RBAC
    serviceDiscovery: Service Discovery
    starred: Starred
    storage: Storage
    workload: Workload
  ns:
    all: All Namespaces
    clusterLevel: Only Cluster Resources
    namespace: "{name}"
    namespaced: Only Namespaced Resources
    orphan: Not in a Project
    project: "Project: {name}"
    system: Only System Namespaces
    user: Only User Namespaces

product:
  apps: Apps & Marketplace
  backup: Rancher Backups
  cis: CIS Benchmark
  ecm: Cluster Manager
  explorer: Cluster Explorer
  fleet: Continuous Delivery
  longhorn: Longhorn
  gatekeeper: OPA Gatekeeper
  istio: Istio
  logging: Logging
  rio: Rio


suffix:
  cpus: CPUs
  ib: iB
  seconds: Seconds

##############################
# Components & Pages
##############################
assignTo:
  title: |-
    {count, plural,
      =1 { Assign Cluster To&hellip; }
      other { Assign {count} Clusters To&hellip; }
    }
  labelsTitle: |-
    {count, plural,
      =1 { Assign Cluster To&hellip; }
      other { Assign {count} Clusters To&hellip; }
    }

asyncButton:
  default:
    action: Action
    waiting: Waiting
    success: Success
    error: Error
  create:
    action:  'Create'
    waiting: 'Creating&hellip;'
    success: 'Created'
  apply:
    action:  'Apply'
    waiting: 'Applying&hellip;'
    success: 'Applied'
  edit:
    action:  'Save'
    waiting: 'Saving&hellip;'
    success: 'Saved'
  delete:
    action:  'Delete'
    waiting: 'Deleting&hellip;'
    success: 'Deleted'
  continue:
    action:  'Continue'
    waiting: 'Saving&hellip;'
    success: 'Saved'
  done:
    action:  'Done'
    waiting: 'Saving&hellip;'
    success: 'Saved'
  enable:
    action:  'Enable'
    waiting: 'Enabling&hellip;'
    success: 'Enabled'
  download:
    action:  'Download'
    waiting: 'Downloading&hellip;'
    success: 'Saving'
  finish:
    action:  'Finish'
    waiting: 'Finishing&hellip;'
    success: 'Finished'
  install:
    action:  'Install'
    waiting: 'Starting&hellip;'
    success: 'Installing'
  upgrade:
    action:  'Upgrade'
    waiting: 'Starting&hellip;'
    success: 'Upgrading'
  refresh:
    action: ''
    actionIcon:  'refresh'
    waiting: ''
    waitingIcon: 'refresh'
    success: ''
    successIcon: 'checkmark'
    error: ''
    errorIcon:   'error'

backupRestoreOperator:
  backupFilename: Backup Filename
  deployment:
    rancherNamespace: Rancher ResourceSet Namespace
    storage:
      tip: Configure a storage location where all backups are saved by default. You will have the option to override this with each backup, but will be limited to using an S3-compatible object store.
      storageClass:
        label: Storage Class
      persistentVolume:
        label: Persistent Volume
      label: Default Storage Location
      options:
        none: No default storage location
        s3: Use an S3-compatible object store
        defaultStorageClass: 'Use the default storage class ({name})'
        pickSC: Use an existing storage class
        pickPV: Use an existing persistent volume
      warning: This {type} does not have its reclaim policy set to "Retain".  Your backups may be lost if the volume is changed or becomes unbound.
    size: Size
  prune:
    label: Prune
    tip: Delete the resources managed by Rancher that are not present in the backup. (Recommended)
  encryption: Encryption
  encryptionConfigName:
    label: Encryption Config Secret
    backuptip: Any secret in the <code>cattle-resource-system</code> namespace that has an <code>encryption-provider-config.yaml</code> key. <br/>The contents of this file are necessary to perform a restore from this backup, and are not stored by Rancher Backup.
    restoretip: If the backup was performed with encryption enabled, a secret containing the same encryption-provider-config should be used during restore.
    options:
      none: Store the contents of the backup unencrypted
      secret: Encrypt backups using an <a target="_blank" rel='noopener nofollow' href="https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/#understanding-the-encryption-at-rest-configuration">Encryption Config Secret</a> (Recommended)
    warning: The contents of this file are necessary to perform a restore from this backup, and are not stored by Rancher Backup.
  deleteTimeout:
    label: Delete Timeout
    tip: Seconds to wait for a resource delete to succeed before removing finalizers to force deletion.
  resourceSetName: Resource Set
  schedule:
    label: Schedule
    placeholder: e.g. @midnight or 0 0 * * *
    options:
      disabled: One-Time Backup
      enabled: Recurring Backups
  restoreFrom:
    existing: An existing backup config
    default: The default storage target
    s3: An S3-compatible object store
  retentionCount:
    label: Retention Count
    units: |-
      {count, plural,
        =1 { File }
        other { Files }
      }
  s3:
    titles:
      backupLocation: Backup Source
      location: Storage Location
      s3: S3
    credentialSecretName:  Credential Secret
    storageLocation: Storage Location
    endpoint: Endpoint
    endpointCA: Endpoint CA
    bucketName: Bucket Name
    region: Region
    folder: Folder
    insecureTLSSkipVerify: Skip TLS Verifications
  storageSource:
    useDefault: Use the default storage location configured during installation
    configureS3: Use an S3-compatible object store
    useBackup: Use the s3 location specified on the Backup CR
  targetBackup: Target Backup
  noResourceSet: 'You must define a ResourceSet in this namespace to create a backup CR.'


catalog:
  repo:
    name:
      'rancher-charts': Rancher
      'rancher-partner-charts': Partners
    all: All
    target:
      label: Target
      git: Git Repository containing Helm chart definitions
      http: http(s) URL to an index generated by Helm
    url:
      label: Index URL
      placeholder: e.g. https://charts.rancher.io
    gitRepo:
      label: Git Repo URL
      placeholder: e.g. https://github.com/your-company/charts.git
    gitBranch:
      label: Git Branch
      placeholder: e.g. master
  charts:
    header: Deploy Chart
    certified:
      rancher: Rancher
      partner: Partner
      other: Other
    search: Filter
  install:
    header:
      upgrade: Upgrade {name}
      install: Install {name}
      installGeneric: Install Chart
    section:
      appReadme: README
      readme: Helm README
      chartOptions: Chart Options
      valuesYaml: Values YAML
      helm: Helm Deploy Options
    appReadmeGeneric: This chart doesn't have a Rancher-specific README.  Review the Helm README to learn more about the available configuration options and their usage.
    project: Install into Project
    helm:
      atomic: Atomic
      cleanupOnFail: Cleanup on Failure
      crds: Apply custom resource definitions
      dryRun: Dry Run
      force: Force
      historyMax:
        label: Keep last
        unit: |-
          {value, plural,
            =1 { revision }
            other { revisions }
          }
      hooks: Execute chart hooks
      openapi: Validate OpenAPI schema
      resetValues: Reset Values
      timeout:
        label: Timeout
        unit: |-
          {value, plural,
            =1 { second }
            other { seconds }
          }
      wait: Wait
  app:
    section:
      readme: Chart README
      notes: Release Notes
      values: Values YAML
      resources: Resources

chartHeading:
  overview: Overview
  poweredBy: "Powered by:"

cis:
  addTest: Add Test ID
  benchmarkVersion: Benchmark Version
  noProfiles: There are no valid ClusterScanProfiles for this cluster type to select.
  profile: Profile
  testID: Test ID
  testsToSkip: Tests to Skip
  scan:
    description: Description
    failed: Failed
    lastScanTime: Last Scan Time
    notApplicable: 'N/A'
    number: Number
    passed: Passed
    scanReport: Scan Report
    skipped: Skipped
    total: Total

cluster:
  nodeDriver:
    displayName:
      aliyun: Alibaba ACK
      aliyunecs: Aliyun ECS
      amazonec2: Amazon EC2
      amazoneks: Amazon EKS
      azure: Azure
      azureaks: Azure AKS
      baidu: Baidu CCE
      cloudca: Cloud.ca
      digitalocean: DigitalOcean
      exoscale: Exoscale
      googlegke: Google GKE
      huaweicce: Huawei CCE
      linode: Linode
      oci: Oracle Cloud Infrastructure
      openstack: OpenStack
      oracleoke: Oracle OKE
      otc: Open Telekom Cloud
      packet: Packet
      pinganyunecs: Pinganyun ECS
      rackspace: RackSpace
      rancherkubernetesengine: RKE
      softlayer: SoftLayer
      tencenttke: Tencent TKE
      upcloud: UpCloud
      vmwarevsphere: vSphere
      zstack: ZStack
  provider:
    aks: Azure AKS
    docker: Docker
    eks: Amazon EKS
    gke: Google GKE
    k3s: K3s
    kubeAdmin: KubeADM
    minikube: Minikube
    other: Other
    rke: RKE
    rke2: RKE Government

clusterIndexPage:
  hardwareResourceGauge:
    consumption: "{useful} of {total} {units} {suffix}"
    coresReserved: Cores Reserved
    coresUsed: Cores Used
    podsReserved: Pods Reserved
    ramReserved: Memory Reserved
    ramUsed: Memory Used
  header: Cluster Dashboard
  resourceGauge:
    totalResources: Total Resources
  sections:
    events:
      label: Events
    gatekeeper:
      buttonText: Configure Gatekeeper
      disabled: OPA Gatekeeper is not configured.
      label: OPA Gatekeeper Constraint Violations
      noRows: There are no contraints with violations to show.
    nodes:
      label: Unhealthy Nodes
      noRows: There are no unhealthy nodes to show.

configmap:
  tabs:
    data:
      label: Data
      protip: Use this area for anything that's UTF-8 text data
    binaryData:
      label: Binary Data

containerResourceLimit:
  cpuPlaceholder: e.g. 1000
  helpText: Configure how much of the resources the container can consume by default.
  helpTextDetail: The amount of resources the container can consume by default.
  label: Container Default Resource Limit
  limitsCpu: CPU Limit
  limitsMemory: Memory Limit
  memPlaceholder: e.g. 128
  requestsCpu: CPU Reservation
  requestsMemory: Memory Reservation

cruResource:
  backToForm: Back to Form
  backBody: You will lose any changes made to the YAML.
  cancelBody: You will lose any changes made to the YAML.
  confirmBack: "Okay"
  confirmCancel: "Okay"
  reviewForm: "Keep editing YAML"
  reviewYaml: "Keep editing YAML"
  previewYaml: Edit as YAML

fleet:
  cluster:
    summary: Resource Summary
    nonReady: Non-Ready Bundles
  fleetSummary:
    state:
      success: 'Ready'
      info: 'Transitioning'
      warning: 'Warning'
      error: 'Error'
      unknown: 'Unknown'
  gitRepo:
    tabs:
      resources: Resources
      unready: Non-Ready
    auth:
      label: Authentication
      none: None
      basic: HTTP Basic Auth
      ssh: SSH Key
      custom: Secret Name
    paths:
      label: Paths
      placeholder: e.g. /directory/in/your/repo
      addLabel: Add Path
    repo:
      label: Repository URL
      placeholder: 'e.g. https://github.com/rancher/fleet-examples.git'
    ref:
      label: Watch
      branch: A Branch
      revision: A Revision
      branchLabel: Branch Name
      branchPlaceholder: e.g. master
      revisionLabel: Tag or Commit Hash
      revisionPlaceholder: e.g. v1.0.0
    target:
      selectLabel: Target Type
      advanced: Advanced
      cluster: Cluster
      clusterGroup: Cluster Group
      label: Deploy To
      labelLocal: Deploy With
    targetDisplay:
      advanced: Advanced
      cluster: "Cluster"
      clusterGroup: "Group"
      all: All
      local: Local
    workspace:
      label: Workspace
  clusterGroup:
    selector:
      label: Cluster Selectors
      matchesAll: Matches all {total, number} existing clusters
      matchesNone: Matches no existing clusters
      matchesSome: |-
        {matched, plural,
          =1 {Matches 1 of {total, number} existing clusters: "{sample}"}
          other {Matches {matched, number} of {total, number} existing clusters, including "{sample}"}
        }

footer:
  docs: Docs
  download: Download CLI
  forums: Forums
  issue: File an Issue
  slack: Slack

gatekeeperConstraint:

  match:
    title: Match
  tab:
    enforcementAction:
      title: Enforcement Action
    kinds:
      title: Kinds
    namespaces:
      sub:
        excludedNamespaces: Excluded Namespaces
        namespaces: Namespaces
      title: Namespaces
    parameters:
      addParameter: Add Parameter
      editAsForm: Edit as Form
      editAsYaml: Edit as YAML
      title: Parameters
    selectors:
      sub:
        labelSelector:
          addLabel: Add Label
          title: Label Selector
        namespaceSelector:
          addNamespace: Add Namespace
          title: Namespace Selector
      title: Selectors
  template: Template
  violations:
    title: Violations

gatekeeperIndex:
  poweredBy: OPA Gatekeeper
  unavailable: OPA + Gatekeeper is not available in the system-charts catalog.
  violations: Violations

glance:
  created: Created
  cpu: CPU Usage
  memory: Memory
  nodes:
    total:
      label: |-
        {count, plural,
          =1 { Node }
          other { Total Nodes }
        }
  pods: Pods
  provider: Provider
  version: Kubernetes Version

ingress:
  certificates:
    addCertificate: Add Certificate
    addHost: Add Host
    certificate:
      label: Certificate - Secret Name
    defaultCertLabel: Default Ingress Controller Certificate
    headers:
      certificate: Certificate
      hosts: Hosts
    host:
      label: Host
      placeholder: e.g. example.com
    label: Certificates
    removeHost: Remove
  defaultBackend:
    label: Default Backend
    noServiceSelected: No default backend is configured.
    port:
      label: Port
      placeholder: e.g. 80 or http
    targetService:
      label: Target Service
      doesntExist: The selected service does not exist
    warning: "Warning: Default backend is used globally for the entire cluster."
  rules:
    addPath: Add Path
    addRule: Add Rule
    headers:
      pathType: Path Type
      path: Path
      port: Port
      target: Target Service
    hostname: Hostname
    path:
      label: Path
      placeholder: e.g. /foo
    port:
      label: Port
      placeholder: e.g. 80 or http
    removePath: Remove
    requestHost:
      label: Request Host
      placeholder: e.g. example.com
    target:
      label: Target Service
      doesntExist: The selected service does not exist

    title: Rules

internalExternalIP:
  none: None

istio:
  links:
    label: Kiali
    description: Visualization of services within a service mesh and how they are connected. For Kiali to display data, you need Prometheus installed. If you need a monitoring solution, install <a tabindex="0" aria-label="Link to Rancher's Monitoring" href="{link}"> Rancher's monitoring</a>.
  cni: Enabled CNI
  customOverlayFile:
    label: Custom Overlay File
    tip: 'The <a target="_blank" rel="noopener noreferrer nofollow" href="https://istio.io/latest/docs/setup/install/istioctl/#customizing-the-configuration">overlay file</a> allows for additional configuration on top of the base Rancher Istio installation. You can utilize the <a href="https://istio.io/latest/docs/reference/config/istio.operator.v1alpha1/" target="_blank" rel="noopener noreferrer nofollow" >IstioOperator API</a> to make changes and additions for all components and apply those changes via this overlay YAML file.'
  description: 'Rancher Istio helm chart installs a minimal Istio configuration for you to get started integrating with your applications.
  If you would like to get additional information about Istio, visit <a target="_blank" href="https://istio.io/latest/docs/concepts/what-is-istio" rel="noopener nofollow">https://istio.io/latest/docs/concepts/what-is-istio/</a>'
  egressGateway: Enabled Egress Gateway
  ingressGateway: Enabled Ingress Gateway
  istiodRemote: Enabled istiodRemote
  pilot: Enabled Pilot
  policy: Enabled Policy
  poweredBy: Powered by <a target="_blank" rel="noopener noreferrer nofollow" href='https://istio.io/latest/'>Istio</a>
  telemetry: Enabled Telemetry
  titles:
    components: Components
    customAnswers: Custom Answers
    advanced: Advanced Settings
    description: Description
  v1Warning: Please uninstall the current Istio version in the <code>istio-system</code> namespace before attempting to install this version.

labels:
  addLabel: Add Label
  addSetLabel: Add/Set Label
  addAnnotation: Add Annotation

logging:
  clusterFlow:
    noOutputsBanner: There are no cluster outputs in the selected namespace.
  flow:
    clusterOutputs:
      label: Cluster Outputs
    matches:
      label: Matches
      addSelect: Add Include Rule
      addExclude: Add Exclude Rule
    filters:
      label: Filters
    outputs:
      label: Outputs
  install:
    k3sContainerEngine: K3S Container Engine
  elasticsearch:
    host: Host
    scheme: Scheme
    port: Port
    indexName: Index Name
    user: User
    password: Password
    caFile:
      label: Certificate Authority File
    clientCert:
      label: Client Cert
      placeholder: Paste in the CA certificate
    clientKey:
      label: Client Key
      placeholder: Paste in the client key
    clientKeyPass: Client Key Pass
  kafka:
    brokers: Brokers
    defaultTopic: Default Topic
    saslOverSsl: SASL Over SSL
    scramMechanism: Scram Mechanism
    username: Username
    password: Password
    sslCaCert:
      label: SSL CA Cert
      placeholder: Paste in the CA certificate
    sslClientCert:
      label: SSL Client Cert
      placeholder: Paste in the client cert
    sslClientCertChain:
      label: SSL Client Cert Chain
      placeholder: Paste in the client cert chain
    sslClientCertKey: SSL Client Cert Key
  output:
    selectOutputs: Select Outputs
    selectBanner: Select to configure an output
    sections:
      target: Target
      access: Access
      certificate: SSL
  outputProviders:
    elasticsearch: Elasticsearch
    splunkHec: Splunk
    kafka: Kafka
    forward: Fluentd
    unknown: Unknown
  overview:
    poweredBy: Banzai Cloud
    clusterLevel: Cluster-Level
    namespaceLevel: Namespace-Level
  provider: Provider
  splunk:
    host: Host
    port: Port
    protocol: Protocol
    index: Index
    token: Token
    clientCert: Client Cert
    clientKey: Client Key
    insecureSsl: Insecure SSL
  forward:
    host: Host
    port: Port
    sharedKey: Shared Key
    username: Username
    password: Password

longhorn:
  overview:
    title: Overview
    subtitle: "Powered By: <a href='https://github.com/longhorn' target='_blank' rel='noopener nofollow' >Longhorn</a>"
    linkedList:
      longhorn:
        label: 'Longhorn'
        description: 'Manage storage system via UI'
        na: Resource Unavailable

monitoring:
  accessModes:
    many: ReadWriteMany
    once: ReadWriteOnce
    readOnlyMany: ReadOnlyMany
  aggregateDefaultRoles: Aggregate to Default Kubernetes Roles
  alerting:
    config:
      label: Alert Manager Cofig
    enable:
      label: Deploy Alertmanager
    secrets:
      additional:
        label: Additional Secrets
        info: "Secrets should be mounted at <pre class='inline-block m-0'>/etc/alertmanager/secrets/</pre>"
      existing: Choose an existing config secret
      info: |+
        <span class="text-bold">Create default config</span>: A Secret containing your Alertmanager Config will be created in the <pre class='inline-block m-0'>cattle-monitoring-system</pre> namespace on deploying this chart under the name <pre class='inline-block m-0'>alertmanager-rancher-monitoring-alertmanager</pre>. By default, this Secret will never be modified on an uninstall or upgrade of this chart. <br />
        Once you have deployed this chart, you should edit the Secret via the UI in order to add your custom notification configurations that will be used by Alertmanager to send alerts. <br /> <br />
        <span class="text-bold">Choose an existing config secret</span>: You must specify a Secret that exists in the <pre class='inline-block m-0'>cattle-monitoring-system</pre> namespace. If the namespace does not exist, you will not be able to select an existing secret.
      label: Alertmanager Secret
      new: Create default config
      radio:
        label: Config Secret
    templates:
      keyLabel: File Name
      label: Template Files
      valueLabel: YAML Template
    title: Configure Alertmanager
  clusterType:
    label: Cluster Type
    placeholder: Select cluster type
  createDefaultRoles: Create Default Monitoring Cluster Roles
  grafana:
    storage:
      annotations: PVC Annotations
      className: Storage Class Name
      existingClaim: Use Existing Claim
      finalizers: PVC Finalizers
      label: Persistent Storage for Grafana
      mode: Access Mode
      selector: Selector
      size: Size
      subpath: Use Subpath
      type: Persistent Storage Types
      types:
        existing: Enable With Existing PVC
        statefulset: Enable with StatefulSet Template
        template: Enable with PVC Template
      volumeMode: Volume Mode
      volumeName: Volume Name
    title: Configure Grafana
  overview:
    title: Dashboard
    subtitle: "Powered By: <a href='https://github.com/coreos/prometheus-operator' target='_blank' rel='noopener nofollow' >Prometheus</a>"
    linkedList:
      alertManager:
        label: 'Alertmanager'
        description: 'Active Alerts'
      grafana:
        label: 'Grafana'
        description: 'Metrics Dashboards'
      na: Resource Unavailable
      prometheusPromQl:
        label: 'Prometheus Graph'
        description: 'PromQL Graph'
      prometheusRules:
        label: 'Prometheus Rules'
        description: 'Configured Rules'
      prometheusTargets:
        label: 'Prometheus Targets'
        description: 'Configured Targets'
    v1Warning: Monitoring is currently deployed from Cluster Manager. If you are migrating from an older version of Rancher with monitoring enabled, please disable monitoring in Cluster Manager before attempting to use monitoring in Cluster Explorer.
  prometheus:
    config:
      adminApi: Admin API
      evaluation: Evaluation Interval
      limits:
        cpu: CPU Limit
        memory: Memory Limit
      requests:
        cpu: Requested CPU
        memory: Requested Memory
      retention: Retention
      retentionSize: Retention Size
      resourceLimits: Resource Limits
      scrape: Scrape Interval
      ignoreNamespaceSelectors:
        label: Namespace Selectors
        radio:
          enforced: "Use: Monitors can access resources based on namespaces that match the namespace selector field"
          ignored: "Ignore: Monitors can only access resources in the namespace they are deployed in"
        help: Ignoring Namespace Selectors allows Cluster Admins to limit teams from monitoring resources outside of namespaces they have permissions to but can break the functionality of Apps that rely on setting up Monitors that scrape targets across multiple namespaces, such as Istio.
    storage:
      className: Storage Class Name
      label: Persistent Storage for Prometheus
      mode: Access Mode
      selector: Selector
      size: Size
      volumeMode: Volume Mode
      volumeName: Volume Name
    title: Configure Prometheus
    warningInstalled: |+
      Warning: Prometheus Operators are currently deployed. Deploying multiple Prometheus Operators onto one cluster is not currently supported. Please remove all other Prometheus Operator deployments from this cluster before trying to install this chart.
      If you are migrating from an older version of Rancher with Monitoring enabled, please disable Monitoring on this cluster completely before attempting to install this chart.
  volume:
    modes:
      block: Block
      file: Filesystem
  v1Warning: Monitoring is currently deployed from Cluster Manager. If you are migrating from an older version of Rancher with monitoring enabled, please disable monitoring in Cluster Manager before attempting to install the new Rancher Monitoring chart in Cluster Explorer.

nameNsDescription:
  name:
    label: Name
    placeholder: 'A unique name'
  namespace:
    label: Namespace
    placeholder:
  workspace:
    label: Workspace
    placeholder:
  description:
    label: Description
    placeholder: Any text you want that better describes this resource

namespace:
  containerResourceLimit: Container Resource Limit

node:
  detail:
    detailTop:
      containerRuntime: Container Runtime
      ipAddress: IP Address
      os: OS
      version: Version
    glance:
      consumptionGauge:
        amount: "{used} of {total} {unit} used"
        cpu: CPU
        memory: MEMORY
        pods: PODS
      diskPressure: Disk Pressure
      kubelet: kubelet
      memoryPressure: Memory Pressure
      pidPressure: PID Pressure
    tab:
      address:
        label: Address
        externalIp: ExternalIP
      conditions: Conditions
      images: Images
      info: Info
      taints: Taints

persistentVolumeClaim:
  accessModes: Access Modes
  capacity: Capacity
  storageClass: Storage Class
  volumes: Persistent Volumes
  volumeName: Persistent Volume Name
  source:
    label: Source
    options:
      new: Use a Storage Class to provision a new Persistent Volume
      existing: Use an existing Persistent Volume
prefs:
  title: Preferences
  theme:
    label: Theme
    light: Light
    auto: Auto
    dark: Dark
    autoDetail: Auto uses OS preference if available, or dark from {pm} to {am}
  landing:
    label: Login Landing Page
    vue: Cluster Explorer
    ember: Cluster Manager
  formatting: Formatting
  dateFormat:
    label: Date Format
  timeFormat:
    label: Time Format
  perPage:
    label: Table Rows per Page
    value: |-
      {count, number}
  keymap:
    label: YAML Editor Key Mapping
    sublime: 'Normal human'
    emacs: 'Emacs'
    vim: 'Vim'
  advanced: Advanced
  dev:
    label: Enable Developer Tools
  hideDesc:
    label: Hide All Type Description Boxes

prometheusRule:
  alertingRules:
    addLabel: Add Alert
    annotations:
      description:
        input: Description Annotation Value
        label: Description
      label: Annotations
      message:
        input: Message Annotation Value
        label: Message
      runbook:
        input: Runbook URL Annotation Value
        label: Runbook URL
      summary:
        input: Summary Annotation Value
        label: Summary
    bannerText: 'When firing alerts, the annotations and labels will be passed to the configured AlertManagers to allow them to construct the notification that will be sent to any configured Receivers.'
    for:
      label: Wait to fire for
      placeholder: '60'
    label: Alerting Rules
    labels:
      label: Labels
      severity:
        choices:
          critical: critical
          label: Severity Label Value
          none: none
          warning: warning
        label: Severity
    name: Alert Name
    removeAlert: Remove Alert
  groups:
    add: Add Rule Group
    groupRowLabel: Rule Group {index}
    groupInterval:
      label: Override Group Interval
      placeholder: '60'
    label: Rule Groups
    name: Group Name
    none: Please add at least one rule group that contains at least one alerting or one recording rule.
    removeGroup: Remove Group
    responseStrategy:
      label: Partial Response Strategy
  promQL:
    label: PromQL Expression
  recordingRules:
    addLabel: Add Record
    label: Recording Rules
    labels: Labels
    name: Time Series Name
    removeRecord: Remove Record

promptRemove:
  andOthers: |-
    {count, plural,
    =0 {.}
    =1 {, and one other.}
    other {, and {count} others.}
    }
  attemptingToRemove: "You are attemping to remove the {type}"
  protip: "Protip: Hold the {alternateLabel} key while clicking delete to bypass this confirmation"

resourceDetail:
  detailTop:
    annotations: Annotations
    created: Created
    deleted: Deleted
    description: Description
    labels: Labels
    ownerReferences: |-
      {count, plural,
      =1 {Owner}
      other {Owners}}
    showAnnotations: |-
      {annotations, plural,
      =1 {Show annotation}
      other {Show {annotations} annotations}}
  header:
    clone: "Clone from {type}: {name}"
    create: Create
    edit: Edit
    stage: "Stage from {type}: {name}"
    view: "{name}"
  masthead:
    age: Age
    defaultBannerMessage:
      error: This resource is currently in an error state, but there isn't a detailed message available.
      transitioning: This resource is currently in a transitioning state,but there isn't a detailed message available.
    namespace: Namespace
    workspace: Workspace
    overview: Overview
    project: Project
    yaml: YAML
    managedWarning: This {type} is managed by the {managedBy} app {appName}; changes made here will likely be overwritten the next time the app is changed.

resourceList:
  head:
    create: Create
    createFromYaml: Create from YAML
    createResource: "Create {resourceName}"

resourceTable:
  groupLabel:
    namespace: "<span>Namespace:</span> {name}"
    notInANamespace: Not Namespaced
    notInAProject: Not in a Project
    project: "<span>Project:</span> {name}"
    notInAWorkspace: Not in a Workspace
    workspace: "<span>Workspace:</span> {name}"

resourceTabs:
  tabs:
    conditions: Conditions
    events: Recent Events

resourceYaml:
  errors:
    namespaceRequired: This resource is namespaced, so a namespace must be provided.
  buttons:
    continue: Continue Editing
    diff: Show Diff

rioConfig:
  configure:
    description: Description
    helpText:
      listItem1: The application deployment engine for Kubernetes.
      listItem2: "Rio makes it faster and easier for DevOps to build, test, deploy, scale and version stateless applications"
    requirements:
      header: Requirements
      helpText:
        listItem1: 1 CPU Core
        listItem2: 2 GiB of Memory
  header: Rio
  yaml:
    buttonText: Customize

secret:
  certificate:
    caCertificate: CA Certificate
    cn: Domain Name
    expires: Expires
    issuer: Issuer
    plusMore: "+ {n} more"
    privateKey: Private Key
  data: Data
  registry:
    address: Type Registry
    domainName: Registry Domain Name
    password: Password
    username: Username
  basic:
    password: Password
    username: Username
  ssh:
    public: Public Key
    private: Private Key
  type: Type

servicePorts:
  header:
    label: Port Rules
  rules:
    listening:
      label: Listening Port
      placeholder: e.g. 8080
    name:
      label: Port Name
      placeholder: e.g. myport
    node:
      label: Node Port
      placeholder: e.g. 80
    protocol:
      label: Protocol
    target:
      label: Target Port
      placeholder: e.g. 80 or http

serviceTypes:
  clusterip: Cluster IP
  externalname: External Name
  headless: Headless
  loadbalancer: Load Balancer
  nodeport: Node Port

servicesPage:
  labelsAnnotations:
    label: Labels & Annotations
  affinity:
    actionLabels:
      clientIp: ClientIP
      none: There is no session affinity configured.
    helpText: Map connections to a consistent target based on their source IP.
    label: Session Affinity
    timeout:
      label: Session Sticky Time
      placeholder: e.g. 10800
  externalName:
    define: Define External Name
    helpText: "External Name is intended to specify a canonical DNS name. To hardcode an IP address, use a Headless service."
    label: External Name
    placeholder: e.g. my.database.example.com
  ips:
    define: Define Service Ports
    clusterIpHelpText: The Cluster IP address must be within the CIDR range configured for the API server.
    external:
      label: External IPs
      placeholder: e.g. 1.1.1.1
      protip: List of IP addresses for which nodes in the cluster will also accept traffic for this service.
    helpText: "Warning: Configuring additional listener IPs is an advanced use case."
    input:
      label: Cluster IP
      placeholder: e.g. 10.0.171.239
    label: Listener IPs
  selectors:
    helpText: "If no selector is created, manual endpoints must be made."
    label: Selectors
  serviceTypes:
    clusterIp:
      abbrv: IP
      description: Exposes the service on a cluster-internal IP. Choosing this value makes the service only reachable from within the cluster. This is the default type.
      label: Cluster IP
    externalName:
      abbrv: EN
      description: "Maps the service to the contents of the `externalName` field (e.g. foo.bar.example.com), by returning a CNAME record with its value. No proxying of any kind is set up."
      label: External Name
    headless:
      abbrv: H
      description: Neither a cluster IP or load balancer is defined. These are used to interface with other service discovery mechanisms outside of Kubernetes implementation. A cluster IP is not allocated and kube-proxy does not handle these services.
      label: Headless
    loadBalancer:
      abbrv: LB
      description: Exposes the service externally using a cloud provider's load balancer.
      label: Load Balancer
    nodePort:
      abbrv: NP
      description: "Exposes the service on each node's IP at a static port (the `NodePort`). You'll be able to contact this type of service, from outside the cluster, by requesting `<NodeIP>:<NodePort>`."
      label: Node Port
  typeOpts:
    label: Service Type

sortableTable:
  actionAvailability:
    selected: "{actionable} selected"
    some: "Available for {actionable} of the {total} selected"
  noData: There are no rows which match your search query.
  noRows: There are no rows to show.
  paging:
    generic: |-
      {pages, plural,
      =0 {No Items}
      =1 {{count} {count, plural, =1 {Item} other {Items}}}
      other {{from} - {to} of {count} Items}}
    resource: |-
      {pages, plural,
      =0 {No {pluralLabel}}
      =1 {{count} {count, plural, =1 {{singularLabel}} other {{pluralLabel}}}}
      other {{from} - {to} of {count} {pluralLabel}}}

tableHeaders:
  address: Address
  age: Age
  apiGroup: API Groups
  branch: Branch
  builtIn: Built In
  bundlesReady: Bundles
  bundleDeploymentsReady: Deployments
  chart: Chart
  clusterCreatorDefault: Cluster Creator Default
  clusterFlow: Cluster Flow
  clusterOutput: Cluster Output
  clusters: Clusters
  clustersReady: Clusters Ready
  clusterGroups: Cluster Groups
  commit: Commit
  condition: Condition
  configuredProviders: Configured Providers
  cpu: CPU
  date: Date
  destination: Target
  download: Download
  effect: Effect
  endpoints: Endpoint
  flow: Flow
  gitRepos: Git Repos
  host: |-
    {count, plural,
      one { Host }
      other { Hosts }
    }
  image: Image
  imageSize: Size
  ingressTarget: Target
  internalExternalIp: External/Internal IP
  key: Key
  keys: Data
  lastUpdated: Last Updated
  lastSeen: Last Seen
  loggingOutputProviders: Providers
  matches: Matches
  message: Message
  name: Name
  nameUnlinked: Name
  namespace: Namespace
  namespaceName: Name
  namespaceNameUnlinked: Name
  node: Node
  nodeName: Name
  nodesReady: Nodes Ready
  object: Object
  output: Output
  p95: 95%tile
  podImages: Image
  pods: Pods
  ram: RAM
  rbac:
    create: Create
    delete: Delete
    get: Get
    list: List
    patch: Patch
    update: Update
    watch: Watch
  ready: Ready
  reason: Reason
  repo: Repo
  reposReady: Repos Ready
  replicas: Replicas
  reqRate: Req Rate
  resource: Resource
  resources: Resources
  rioImage: Image
  roles: Roles
  scale: Scale
  selector: Selector
  simpleName: Name
  simpleScale: Scale
  simpleType: Type
  state: State
  status: Status
  success: Success
  summary: Summary
  target: Target
  targetKind: Target Type
  targetPort: Target
  type: Type
  updated: Updated
  upgrade: Upgradable
  url: URL
  userDisplayName: Display Name
  userId: ID
  userStatus: Status
  username: Username
  value: Value
  version: Version
  weight: Weight

validation:
  arrayLength:
    between: '"{key}" should contain between {min} and {max} {max, plural, =1 {item} other {items}}'
    exactly: '"{key}" should contain {count, plural, =1 {# item} other {# items}}'
    max: '"{key}" should contain at most {count} {count, plural, =1 {item} other {items}}'
    min: '"{key}" should contain at least {count} {count, plural, =1 {item} other {items}}'
  chars: '"{key}" contains {count, plural, =1 {an invalid character} other {# invalid characters}}: {chars}'
  custom:
    missing: 'No validtor exists for { validatorName }! Does the validtor exist in custom-validtors? Is the name spelled correctly?'
  dns:
    doubleHyphen: '"{key}" Cannot contain two or more consecutive hyphens'
    hostname:
      empty: '"{key}" must be at least one character'
      emptyLabel: '"{key}" cannot contain two consecutive dots'
      endDot: '"{key}" cannot end with a dot'
      endHyphen: '"{key}" cannot end with a hyphen'
      startDot: '"{key}" cannot start with a dot'
      startHyphen: '"{key}" cannot start with a hyphen'
      startNumber: '"{key}" cannot start with a number'
      tooLong: '"{key}" cannot be longer than {max} characters'
      tooLongLabel: '"{key}" cannot contain a section longer than {max} characters'
    label:
      emptyLabel: '"{key}" cannot be empty'
      endHyphen: '"{key}" cannot end with a hyphen'
      startHyphen: '"{key}" cannot start with a hyphen'
      startNumber: '"{key}" cannot start with a number'
      tooLongLabel: '"{key}" cannot be more than {max} characters'
  flowOutput:
    both: Requires "Output" or "Cluster Output" to be selected.
    global: Requires "Cluster Output" to be selected.
  k8s:
    identifier:
      emptyLabel: '"{key}" cannot have an empty key'
      emptyPrefix: '"{key}" cannot have an empty prefix'
      endLetter: '"{key}" must end with a letter or number'
      startLetter: '"{key}" must start with a letter or number'
      tooLongKey: '"{key}" cannot have a key longer than {max} characters'
      tooLongPrefix: '"{key}" cannot have a prefix longer than {max} characters'
  noSchema: No schema found to validate
  noType: No type to validate
  number:
    between: '"{key}" should be between {min} and {max}'
    exactly: '"{key}" should be exactly {val}'
    max: '"{key}" should be at most {val}'
    min: '"{key}" should be at least {val}'
  prometheusRule:
    groups:
      required: At least one rule group is required.
      singleAlert: A rule may contain alert rules or recording rules but not both.
      valid:
        name: 'Name is required for rule group {index}.'
        rule:
          alertName: 'Rule group {groupIndex} rule {ruleIndex} requires a Alert Name.'
          expr: 'Rule group {groupIndex} rule {ruleIndex} requires a PromQL Expression.'
          labels: 'Rule group {groupIndex} rule {ruleIndex} requires at least one label. Severity is recommended.'
          recordName: 'Rule group {groupIndex} rule {ruleIndex} requires a Time Series Name.'
        singleEntry: 'At least one alert rule or one recording rule is required in rule group {index}.'
  required: '"{key}" is required'
  requiredOrOverride: '"{key}" is required or must allow override'
  service:
    externalName:
      none: External Name is required on an ExternalName Service.
    ports:
      name:
        required: 'Port Rule [{position}] - Name is required.'
      nodePort:
        requriedInt: 'Port Rule [{position}] - Node Port must be interger values if included.'
      port:
        required: 'Port Rule [{position}] - Port is required.'
        requriedInt: 'Port Rule [{position}] - Port must be interger values if included.'
      targetPort:
        between: 'Port Rule [{position}] - Target Port must be between 1 and 65535'
        iana: 'Port Rule [{position}] - Target Port must be an IANA Service Name or Integer'
        ianaAt: 'Port Rule [{position}] - Target Port '
        required: 'Port Rule [{position}] - Target Port is required'
  stringLength:
    between: '"{key}" should be between {min} and {max} {max, plural, =1 {character} other {characters}}'
    exactly: '"{key}" should be {count, plural, =1 {# character} other {# characters}}'
    max: '"{key}" should be at most {count} {count, plural, =1 {character} other {characters}}'
    min: '"{key}" should be at least {count} {count, plural, =1 {character} other {characters}}'
  targets:
    missingProjectId: A target must have a project selected.

wizard:
  back: Back
  finish: Finish
  next: Next
  step: "Step {number}:"

wm:
  connection:
    connected: Connected
    connecting: Connecting&hellip;
    disconnected: Disconnected
    error: Error
  containerLogs:
    clear: Clear
    containerName: "Container: {label}"
    download: Download
    follow: Follow
    noData: There are no log entries to show in the current range.
    noMatch: No lines match the current filter.
    previous: Use Previous Container
    range:
      all: Everything
      hours: |-
        {value, number}
        {value, plural,
        =1 {Hour}
        other {Hours}
        }
      label: Show the last
      lines: "{value, number} Lines"
      minutes: |-
        {value, number} {value, plural,
        =1 {Minute}
        other {Minutes}
        }
    search: Filter
    timestamps: Show Timestamps
    wrap: Wrap Lines
  containerShell:
    clear: Clear
    containerName: "Container: {label}"
  kubectlShell:
    title: "Kubectl: {name}"

workload:
  container:
    command:
      addFromResource: Add from Resource
      args: Arguments
      as: as
      command: Command
      env: Environment Variables
      fromResource:
        key:
          label: Key
          placeholder: e.g. requests.cpu
        prefix: Prefix or Alias
        source:
          label: Source
          placeholder: e.g. my-container
        type: Type
      workingDir: WorkingDir
    healthCheck:
      checkInterval: Check Interval
      command:
        command: Command to run
      failureThreshold: Failure Threshold
      httpGet:
        headers: Request Headers
        path: Request Path
        port: Check Port
      initialDelay: Initial Delay
      livenessProbe: Liveness Probe
      livenessTip: Containers will be restarted when this check is failing.  Not recommended for most uses.
      noHealthCheck: "There is not a Readiness Check, Liveness Check or Startup Check configured."
      readinessProbe: Readiness Probe
      readinessTip: Containers will be removed from service endpoints when this check is failing.  Recommended.
      startupProbe: Startup Probe
      startupTip: Containers will wait until this check succeeds before attempting other health checks.
      successThreshold: Success Threshold
      timeout: Timeout
    image: Container Image
    imagePullPolicy: Image Pull Policy
    name: Container Name
    noResourceLimits: There are no resource requirements configured.
    noPorts: There are no ports configured.
    ports:
      containerPort: Private Container Port
      hostPort: Public Host Port
      name: Name
      protocol: Protocol
    security:
      addCapabilities: Add Capabilities
      addGroupIDs: Add Group IDs
      allowPrivilegeEscalation: Privilege Escalation
      dropCapabilities: Drop Capabilities
      fsGroup: Filesystem Group
      hostIPC: Use Host IPC Namespace
      hostPID: Use Host PID Namespace
      privileged: Privileged
      readOnlyRootFilesystem: Read-Only Root Filesystem
      runAsGroup: Run as Group ID
      runAsNonRoot: Run as Non-Root
      runAsNonRootOptions:
        noOption: "No"
        yesOption: "Yes: containers must run as non-root-user"
      runAsUser: Run as User ID
      shareProcessNamespace: Share single process namespace
      supplementalGroups: Additional Group IDs
      sysctls: Sysctls
      sysctlsKey: Name
    titles:
      container: Define Container
      command: Command
      containers: Containers
      env: Environment Variables
      events: Events
      healthCheck: Health Check
      image: Image
      networking: Networking
      podAnnotations: Pod Annotations
      podLabels: Pod Labels
      podScheduling: Pod Scheduling
      nodeScheduling: Node Scheduling
      ports: Ports
      resources: Resources
      securityContext: Security Context
      status: Status
      volumeClaimTemplates: Volume Claim Templates
  cronSchedule: Schedule
  detailTop:
    node: Node
    podIP: Pod IP
    podRestarts: Pod Restarts
    workload: Workload
  hideTabs: 'Hide Advanced Options'
  job:
    activeDeadlineSeconds:
      label: Active Deadline
      tip: The duration that the job may be active before the system tries to terminate it.
    backoffLimit:
      label: Back Off Limit
      tip: The number of retries before marking this job failed.
    completions:
      label: Completions
      tip: The number of successfully finished pods the job should be run with.
    failedJobsHistoryLimit:
      label: Failed Job History Limit
      tip: The number of failed finished jobs to retain.
    parallelism:
      label: Parallelism
      tip: The maximum number of pods the job should run at any given time.
    startingDeadlineSeconds:
      label: Starting Deadline Seconds
      tip: The deadline in seconds for starting the job if it misses scheduled time
    successfulJobsHistoryLimit:
      label: Successful Job History Limit
      tip: The number of successful finished jobs to retain.
    suspend: Suspend
  networking:
    dnsPolicy:
      label: DNS Policy
      options:
        clusterFirst: Cluster First
        clusterFirstWithHostNet: Cluster First With Host Network
        default: Default
        none: None
      placeholder: Select a Policy...
    hostAliases:
      add: Add Alias
      keyLabel: IP Address
      keyPlaceholder: e.g. 1.1.1.1
      label: Host Aliases
      tip: Additional /etc/hosts entries to be injected in the container.
      valueLabel: Hostname
      valuePlaceholder: "e.g. foo.com, bar.com"
    hostname:
      label: Hostname
      placeholder: e.g. web
    nameservers:
      add: Add Nameserver
      label: Nameservers
      placeholder: e.g. 1.1.1.1
    networkMode:
      label: Network Mode
      options:
        hostNetwork: Host Network
        normal: Normal
      placeholder: Select a Mode...
    dns: DNS
    resolver:
      label: Resolver Options
      add: Add Option
    searches:
      add: Add Search Domain
      label: Search Domains
      placeholder: e.g. mycompany.com
    subdomain:
      label: Subdomain
      placeholder: e.g. web
  replicas: Replicas
  showTabs: 'Show Advanced Options'
  scheduling:
    activeDeadlineSeconds: Pod Active Deadline
    activeDeadlineSecondsTip: The duration that the pod may be active before the system tries to mark it failed and kill associated containers.
    affinity:
      addNodeSelector: Add Node Selector
      affinityTitle: Run pods on nodes with pods matching these selectors
      antiAffinityTitle: Run pods on nodes without pods matching these selectors
      matchExpressions:
        addRule: Add Rule
        doesNotExist: Does Not Exist
        exists: Exists
        greaterThan: ">"
        in: =
        inNamespaces: "Pods in these namespaces:"
        key: Key
        lessThan: <
        notIn: â‰ 
        operator: Operator
        value: Value
        weight: Weight
      noPodRules: There are no pod scheduling rules configured.
      nodeName: Node Name
      preferAny: "Prefer any of:"
      requireAny: "Require any of:"
      schedulingRules: Run pods on node(s) matching these scheduling rules
      specificNode: Run pods on specific node(s)
      thisPodNamespace: This pod's namespace
      topologyKey:
        label: Topology Key
        placeholder: e.g. failure-domain.beta.kubernetes.io/zone
    priority:
      className: Priority Class Name
      priority: Priority
    terminationGracePeriodSeconds: Termination Grace Period
    terminationGracePeriodSecondsTip: The duration that the pod needs to terminate gracefully.
    titles:
      advanced: Advanced
      nodeScheduling: Node Scheduling
      nodeSelector: Nodes with these labels
      podScheduling: Pod Scheduling
      priority: Priority
      tab: Scheduling
      tolerations: Tolerations
    tolerations:
      addToleration: Add Toleration
      effect: Effect
      effectOptions:
        all: All
        noExecute: NoExecute
        noSchedule: "NoSchedule,"
        preferNoSchedule: PreferNoSchedule
      labelKey: Label Key
      operator: Operator
      operatorOptions:
        equal: =
        exists: Exists
      tolerationSeconds: Toleration Seconds
      value: Value
  serviceName: Service Name
  storage:
    subtypes:
      secret: Secret
      configMap: ConfigMap
      hostPath: Bind-Mount
      persistentVolumeClaim: Persistent Volume Claim
      createPVC: Create Persistent Volume Claim
      csi: CSI
      nfs: NFS
      awsElasticBlockStore: Amazon EBS Disk
      azureDisk: Azure Disk
      azureFile: Azure File
      gcePersistentDisk: Google Persistent Disk
      driver.longhorn.io: Longhorn
      vsphereVolume: VMWare vSphere Volume
    addClaim: Add Claim
    addMount: Add Mount
    addVolume: Add Volume
    certificate: Certificate
    csi:
      diskName: Disk Name
      diskURI: Disk URI
      cachingMode:
        label: Caching Mode
        options:
          none: None
          readOnly: Read Only
          readWrite: Read Write
      kind:
        label: Kind
        options:
          dedicated: Dedicated
          managed: Managed
          shared: Shared
      drivers:
        driver.longhorn.io: Longhorn
      fsType: Filesystem Type
      shareName: Share Name
      secretName: Secret Name
      volumeID: Volume ID
      partition: Partition
      pdName: Persistent Disk Name
      storagePolicyID: Storage Policy ID
      storagePolicyName: Storage Policy Name
      volumePath: Volume Path
    defaultMode: Default Mode
    hostPath:
      label: The Path on the Node must be
      options:
        default: 'Anything: do not check the target path'
        directoryOrCreate: A directory, or create if it doesn't exist
        directory: An existing directory
        fileOrCreate: A file, or create if it doesn't exist
        file: An existing file
        socket: An existing socket
        charDevice: An existing character device
        blockDevice: An existing block device
    mountPoint: Mount Point
    nodePath: Path on Node
    optional:
      label: Optional
      'no': 'No'
      'yes': 'Yes'
    path: Path
    readOnly: Read Only
    server: Server

    subPath: Sub Path in Volume
    title: 'Storage'
    volumeName: Volume Name
    volumePath: Volume Path
  typeDescriptions:
    apps.daemonset: DaemonSets run exactly one pod on every eligible node. When new nodes are added to the cluster, DaemonSets automatically deploy to them. Recommended for system-wide or vertically-scalable workloads that never need more than one pod per node.
    apps.deployment: Deployments run a scalable number of replicas of a pod distributed among the eligible nodes. Changes are rolled out incrementally and can be rolled back to the previous revision when needed. Recommended for stateless & horizontally-scalable workloads.
    apps.statefulset: StatefulSets manage stateful applications and provide guarantees about the ordering and uniqueness of the pods created. Recommended for workloads with persistent storage or strict identity, quorum, or upgrade order requirements.
    batch.cronjob: CronJobs create Jobs, which then run Pods, on a repeating schedule. The schedule is expressed in standard Unix cron format, and uses the timezone of the Kubernetes control plane (typically UTC).
    batch.job: Jobs create one or more pods to reliably perform a one-time task by running a pod until it exits successfully. Failed pods are automatically replaced until the specified number of completed runs has been reached. Jobs can also run multiple pods in parallel or function as a batch work queue.
  upgrading:
    activeDeadlineSeconds:
      label: Pod Active Deadline
      tip: The duration the pod may be active before the system will try to mark it failed and kill associated containers.
    concurrencyPolicy:
      label: Concurrency
      options:
        allow: Allow CronJobs to run concurrently
        forbid: Skip next run if current run hasn't finished
        replace: Replace run if current run hasn't finished
    maxSurge:
      label: Max Surge
      tip: The maximum number of pods allowed beyond the desired scale at any given time.
    maxUnavailable:
      label: Max Unavailable
      tip: The maximum number of pods which can be unavailable at any given time.
    minReadySeconds:
      label: Minimum Ready
      tip: The minimum duration a pod should be ready without containers crashing for it to be considered available.
    podManagementPolicy:
      label: Pod Management Policy
    progressDeadlineSeconds:
      label: Progress Deadline
      tip: The minimum duration to wait for a deployment to progress before marking it failed.
    revisionHistoryLimit:
      label: Revision History Limit
      tip: The number of old ReplicaSets to retain for rollback.
    strategies:
      labels:
        delete: "On Delete: New pods are only created when old pods are manually deleted."
        recreate: "Recreate: Kill ALL pods, then start new pods."
        rollingUpdate: "Rolling Update: Create new pods, until max surge is reached, before deleting old pods. Don't stop more pods than max unavailable."
    terminationGracePeriodSeconds:
      label: Termination Grace Period
      tip: The duration the pod needs to terminate successfully.
    title: upgrading


##############################
# Model Properties
##############################
model:
  account:
    kind:
      admin: Admin
      agent: Agent
      project: Environment
      registeredAgent: Registered Agent
      service: Service
      user: User
  "catalog.cattle.io.app":
    firstDeployed: First Deployed
    lastDeployed: Last Deployed
  cluster:
    name: Cluster Name
  ingress:
    displayKind: L7 Ingress
  machine:
    role:
      controlPlane: Control Plane
      etcd: etcd
      worker: Worker
  openldapconfig:
    domain:
      help: Only users below this base will be used.
      label: User Search Base
      placeholder: "e.g. ou=Users,dc=mycompany,dc=com"
    server:
      label: Hostname or IP Address
    serviceAccountPassword:
      label: Service Account Password
    serviceAccountUsername:
      label: Service Account Username
  projectMember:
    role:
      member: Member
      owner: Owner
      readonly: Read-Only
      restricted: Restricted
  service:
    displayKind:
      generic: Service
      loadBalancer: L4 Balancer

typeDescription:
  # Map of
  # type: Description to be shown on the top of list view describing the type.
  #       Should fit on one line.
  #       If you link to anything external, it must have
  #       target="_blank" rel="noopener noreferrer nofollow"
  cis.cattle.io.clusterscanbenchmark: A benchmark version is the name of benchmark to run using kube-bench as well as the valid configuration parameters for that benchmark.
  cis.cattle.io.clusterscanprofile: A profile is the configuration for the CIS scan, which is the benchmark versions to use and any specific tests to skip in that benchmark.
  cis.cattle.io.clusterscan: A scan is created to trigger a CIS scan on the cluster based on the defined profile. A report is created after the scan is completed.
  cis.cattle.io.clusterscanreport: A report is the result of a CIS scan of the cluster.
  resources.cattle.io.backup: A backup is created to perform one-time backups or schedule recurring backups based on a ResourceSet.
  resources.cattle.io.restore: A restore is created to trigger a restore to the cluster based on a backup file.
  resources.cattle.io.resourceset: A resource set defines which CRDs and resources to store in the backup.
  monitoring.coreos.com.servicemonitor: A service monitor defines the group of services and the endpoints that Prometheus will scrape for metrics. This is the most common way to define metrics collection.
  monitoring.coreos.com.podmonitor: A pod monitor defines the group of pods that Prometheus will scrape for metrics. The common way is to use service monitors, but pod monitors allow you to handle any situation where a service monitor wouldn't work.
  monitoring.coreos.com.prometheusrule: A Prometheus Rule resource defines both recording and/or alert rules. A recording rule can pre-compute values and save the results. Alerting rules allow you to define conditions on when to send notifications to AlertManager.
  monitoring.coreos.com.prometheus: A Prometheus server is a Prometheus deployment whose scrape configuration and rules are determined by selected ServiceMonitors, PodMonitors, and PrometheusRules and whose alerts will be sent to all selected Alertmanagers with the custom resource's configuration.
  monitoring.coreos.com.alertmanager: An alert manager is deployment whose configuration will be specified by a secret in the same namespace, which determines which alerts should go to which receiver.
  catalog.cattle.io.clusterrepo: A chart repository is a Helm repository or Rancher's git based application catalog. It provides the list of available charts in the cluster.
  catalog.cattle.io.operation: An operation is the list of recent Helm operations that have been applied to the cluster.
  catalog.cattle.io.app: An installed application is a Helm 3 chart that was installed either via our charts or through the Helm CLI.
  logging.banzaicloud.io.clusterflow: A cluster flow defines which logs from the entire cluster to collect and filter as well as which output to send the logs. The cluster flow needs to be deployed in the namespace that the logging operator is in.
  logging.banzaicloud.io.flow: A flow defines which logs to collect and filter as well as which output to send the logs. The flow is a namespaced resource, which means logs will only be collected from the namepsace that the flow is deployed in.
  logging.banzaicloud.io.clusteroutput: A cluster output defines which logging providers that logs can be sent to and is only effective when deployed in the namespace that the logging operator is in.
  logging.banzaicloud.io.output: An output defines which logging providers that logs can be sent to. The output needs to be in the same namespace as the flow that is using it.
  logging: To collect and ship your logs you will need to define a Flow and an Output. A Flow defines which logs to collect, filters, and an output which to send the logs. If you would like to collect all logs in the cluster, you can create a ClusterFlow. Outputs can be defined at the namespace level or defined at the cluster level and used by both Flow types.

typeLabel:
  cis.cattle.io.clusterscan: |-
    {count, plural,
      one { Scan }
      other { Scans }
    }
  cis.cattle.io.clusterscanprofile: |-
    {count, plural,
      one { Profile }
      other { Profiles }
    }
  cis.cattle.io.clusterscanbenchmark: |-
    {count, plural,
      one { Benchmark Version }
      other { Benchmark Versions }
    }
  catalog.cattle.io.operation: |-
    {count, plural,
      one { Recent Operation }
      other { Recent Operations }
    }
  catalog.cattle.io.app: |-
    {count, plural,
      one { Installed App }
      other { Installed Apps }
    }
  catalog.cattle.io.clusterrepo: |-
    {count, plural,
      one { Chart Repository }
      other { Chart Repositories }
    }
  catalog.cattle.io.repo: |-
    {count, plural,
      one { Namespaced Repo }
      other { Namespaced Repos }
    }
  chartInstallAction: |-
    {count, plural,
      one { App }
      other { Apps }
    }
  chartUpgradeAction: |-
    {count, plural,
      one { App }
      other { Apps }
    }
  endpoints: |-
    {count, plural,
      one { Endpoint }
      other { Endpoints }
    }
  fleet.cattle.io.cluster: |-
    {count, plural,
      =1 { Cluster }
      other {Clusters }
    }
  fleet.cattle.io.clustergroup: |-
    {count, plural,
      one { Cluster Group }
      other {Cluster Groups }
    }
  fleet.cattle.io.gitrepo: |-
    {count, plural,
      one { Git Repo }
      other {Git Repos }
    }
  management.cattle.io.fleetworkspace: |-
    {count, plural,
      one { Workspace }
      other { Workspaces }
    }
  # pruh-mee-thee-eyes https://www.prometheus.io/docs/introduction/faq/#what-is-the-plural-of-prometheus
  monitoring.coreos.com.prometheus: |-
    {count, plural,
      one { Prometheus }
      other { Prometheis }
    }
  monitoring.coreos.com.servicemonitor: |-
    {count, plural,
      one { Service Monitor }
      other { Service Monitors }
    }
  monitoring.coreos.com.alertmanager: |-
    {count, plural,
      one { Alert Manager }
      other { Alert Managers }
    }
  monitoring.coreos.com.podmonitor: |-
    {count, plural,
      one { Pod Monitor }
      other { Pod Monitors }
    }
  monitoring.coreos.com.prometheusrule: |-
    {count, plural,
      one { Prometheus Rule }
      other { Prometheus Rules }
    }
  monitoring.coreos.com.thanosruler: |-
    {count, plural,
      one { Thanos Rule }
      other { Thanos Rules }
    }
  monitoring.coreos.com.receiver: |-
    {count, plural,
      one { Receiver }
      other { Receivers }
    }
